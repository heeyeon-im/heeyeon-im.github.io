---
title: Research Projects
layout: tag
permalink: /projects/
nohead: true
---
My research projects aim to identify how brain dynamics guide goal-directed, adaptive behaviors in human. Specific contributions of my research projects to the field highlight interactions between object-based and ensemble-based representations, between selective and non-selective pathways, and between perceptual and action control processes. My research suggests that goal-driven behaviors are effectively supported by multiple streams of such parallel processes. This stands in contrast to traditional theories of serial, non-overlapping processing stages across perception, cognition, and action: Instead of simplifying that action is the aftermath of cognition or perception, a new model needs to include effects of continuous interactions across perception, cognition, and action control processes, which can be observed by measuring dynamic connections between brain and behavior. 

__[ Research themes ]__<br/>
[1. Perceptual flexibility empowers cognitive capabilities and action outcomes.](#Research_theme_1)<br/>
[2. Action goals guide perception.](#Research_theme_2)<br/>
[3. Attentional distraction can facilitate perception and action.](#Research_theme_3)<br/>
[4. Individual differences in perception, cognition, and action](#Research_theme_4)<br/>

------

## **1. Perceptual flexibility empowers cognitive capabilities and action outcomes.** {#Research_theme_1}
The visual system reorganizes complex visual scenes using strategies for forming coherent and concise representations, rather than passively receiving all (millions of) bits of information hitting our retinas at any given moment. One powerful heuristic for this is to represent sets of similar objects as an **_ensemble_** using summary statistics such as mean, numerosity, and variance, etc. 
<div class="container"> 
  <div class="row" style="margin-bottom: 0px">
    <div class="col-md-1 col-sm-12">
    </div>      
    <div class="col-md-11 col-sm-12">
        <img src="../images/Visualworld.jpg" width="90%" />
    </div>
  </div>
</div>
<br>
Ensemble perception makes great intuitive sense. If we look around, we always find some redundancy and regularity in the real world images: Buildings in a city, trees in a forest, and fruits in a bush, for example, are often seen as groups of similar but not identical objects. For most everyday needs, we may not need to store individuating information from these scenes. We can instead represent structures, patterns, and gists in a succinct and compact manner. Such perceptual ability to extract ensemble representations from complex scenes can allow our brain to "do more with less" and better understand and interact with visual environments. One line of my research program investigates how our brain achieves this feat and how ensemble perception empowers our perceptual, cognitive, and action control abilities in many different ways.
<br/>

__* Ensemble perception as a strategy for coping with limitations on cognitive abilities__ 
Representing and storing an ensemble (e.g., average) of multiple objects can help the visual system to maintain and recall individual features of the elements better. At the object level, only a few items may be remembered; the rest may be missed completely due to the limited memory capacity. When attempting to recall missed objects, one would have to make random guesses, increasing the overall expected error.However, average information about the set can guide one to recall the missed object to some extent by retrieving values biased toward the average of the set.
Say you try to remember the different colors of six disks in a visual array and report the colors you remember. If you remember only the colors of three disks and completely missed the others, you cannot avoid making extreme errors for the three forgotten colors (e.g., by randomly choosing "red" for a blue disk). However, if you remember that the disks were in ‘cool’ colors on average (even if you cannot remember the exact colors for each disk), it is likely that you will reduce the overall error by choosing six colors from only the continuum of ‘cool’ colors and avoid ‘warm’ colors such as red or orange ([Im & Chong, 2014](../Im, Chong_Perception_2014.pdf)).
<div class="container"> 
  <div class="row" style="margin-bottom: 0px">    
    <div class="col-md-1 col-sm-12">
    </div>     
    <div class="col-md-11 col-sm-12">
        <img src="../images/RememberColor3.jpg" width="90%" />
    </div>
  </div>
</div>
<br/>
Moreover, I have discovered that a visual image in which individual items are spatially grouped together allows the visual system to extract, select, and remember more ensembles from the image, compared to that of individuals that are spatially intermixed ([Im & Chong, 2014](../Im, Chong_Perception_2014.pdf); [Im, Park, & Chong, 2015](../Imetal_JCP_2015.pdf); see Demos [here](https://heeyeon-im.github.io/demo/)). This suggests that reconstructing individuals in a visual scene in a coherent manner (e.g., sets or ensembles) is an efficient strategy to increase our memory capacity. 
<div class="container"> 
  <div class="row" style="margin-bottom: 1px">   
    <div class="col-md-6 col-sm-12">
        <img src="../images/Meansize5.jpg" width="120%" />
    </div>    
    <div class="col-md-6 col-sm-12">
This is somewhat equivalent to using a "chunking" or "binding" approach for our verbal memory to reducing the amount of information we have to deal with at once (e.g., recoding the separate letters F-B-I-C-I-A-N-S-A into three words, FBI, CIA, and NSA). My findings in this line of research suggest that 
    </div>      
  </div>
</div>
ensemble perception allows us to compress information of individuals in a visual image into a compact and meaningful "chunks", saving cognitive resources that can be used to process and remember more information about the scene.   
<br/>
__* Hierarchical coding of a visual scene: Objects and Ensembles__<br/>
My findings in this research program specify a critical new aspect of the structure of visual perception by demonstrating that multiple ensembles of items, up to 3~4 sets, can be extracted in parallel, as higher-order units for visual perception and memory. The limit on the number of ensembles that can be extracted at any given time also converges with the three-or-four-object limits of visual attention (e.g., [Pylyshyn & Storm, 1988](https://www.ncbi.nlm.nih.gov/pubmed/3153671)) and visual working memory (e.g., [Alvarez & Cavanagh, 2004](https://www.ncbi.nlm.nih.gov/pubmed/14738517); [Luck & Vogel, 1997](https://www.ncbi.nlm.nih.gov/pubmed/9384378); [Zhang & Luck, 2008](https://www.ncbi.nlm.nih.gov/pubmed/18385672)). 
<div class="container"> 
  <div class="row" style="margin-bottom: 1px">    
    <div class="col-md-5 col-sm-12">
        <img src="../images/hierarchical_coding3.jpg" width="100%" />
    </div> 
    <div class="col-md-7 col-sm-12">
Such convergence illustrates how items in a visual scene can be represented hierarchically. At least two units of visual processing - individual object and ensemble - can be extracted from a visual scene to be available at the same time, providing complementary         
    </div>     
  </div>
</div>
information on different aspects of scenes. For example, a single display of 5 red, 5 blue, 5 yellow, and 5 green dots can be represented as four color sets or 20 separate dots. At one level, "the set of blue dots" may be selected and only its average information (e.g., mean size, center location, etc.) may be stored as a single individual in visual working memory. At another level, "the set of blue dots" may be treated as 5 distinct items, available for individual size comparison, for example. This distinction highlights a hierarchical coding of "ensemble" and "individual" that is important for making sense of visual scenes. 

In order to investigate the nature of hierarchical coding of ensembles and individuals, one of my research projects ([Im, Zhong, & Halberda, 2016](../Imetal_VR_2016.pdf), see Demo [here](https://heeyeon-im.github.io/demo/)) employed a computer vision algorithm to characterize and predict human observers' patterns of grouping multiple dots into sets based on spatial proximity. Human observers' grouping pattern was surprisingly consistent with one another, even though they were instructed to group the dots in whatever way they felt the most comfortable and natural. This suggests that most of us may share the basic visual concept of "a group" or "a set" and we likely perceive "groups of dots" from a visual scene in a similar manner.     
<div class="container"> 
  <div class="row" style="margin-bottom: 1px">
    <div class="col-md-4 col-sm-12">
        <img src="../images/grouping_fig3.jpg" width="90%" />
    </div>
    <div class="col-md-8 col-sm-12">
And more importantly, I have found that the way observers grouped the dots into sets (predicted by the model uisng my clustering algorithm) systematically modulated the way they estimated the number of individual dots. Although Images A and B both had 29 dots, the estimated number of individual dots by human observers were dramatically different, with Image B (more clustered) being perceived as having much fewer dots than Image A (less clustered). My clustering algorithm could accurately predict the degree to which observers underestimated the number of individual dots, depending on the degree to which individual dots were spatially clustered into groups. This finding provides an example of how
    </div>
  </div>
</div>
representations of "sets" and "individual objects" are extracted from the same image to interact with each other: The way dots are grouped and clustered modulates visual impression of number of the individuals, just as the way individuals are positioned modulates the way they are grouped into a set.
<br/>
Together, representing different perceptual units from a scene allows the visual system to be able to utilze more information with less mental resource. By combining these different levels of representation of objects and ensembles, the visual system can perceive, and we can remember, the visual scene with greater detail, which can then effectively guide better action outcomes. 

------
## **2. Action goals guide perception.** {#Research_theme_2}
For decades, prevailing models of human behavior assume a functional structure of serial processing stages of perception, cognition, and action control modules. Thus the relationship between perception and motor system has been viewed as unidirectional; and the role of motor control system is only considered as final outcome of commands from perceptual and cognitive systems. However, I have discovered behavioral and neural evidence for continuous interactions between perception and action that are bidirectional. For example, I have found that different social motivations and action goals (e.g., approach and avoidance) modulate the way we perceive emotional states and behavioral intent of crowds of people ([Im et al., 2017a](../Im_etal_NHB_2017.pdf); [Im et al., 2017b](../Im_etal_Cult_Br_2017.pdf), see Demo [here](https://heeyeon-im.github.io/demo/)). 
<div class="container"> 
  <div class="row" style="margin-bottom: 1px">
    <div class="col-md-4 col-sm-12">
        <img src="../images/Faces1.jpg" width="85%" />
    </div>
    <div class="col-md-8 col-sm-12">
When the observers’ goal was to avoid a potential threat in a social environment, they recognized a crowd of angry faces (Image A) much more accurately and rapidly than a crowd of happy faces. Conversely, when the goal was to approach a friendly group, a happy crowd (Image B) was perceived more accurately than an angry crowd. This suggests that our goals for ongoing interactions with the external world influences the way we perceive the world. 
    </div>
  </div>
</div>
<br/>
__* Functionally and neurally differential processing routes for perceiving social visual cues__<br/>
My fMRI and MEG data further show that there are (at least) two different processing routes for perceiving and responding to social visual cues: a fast processing route along the dorsal pathway in the brain for global perception of, and fast reaction to, social crowds and a slower processing route along the ventral pathway for local and detailed perception of individual faces. Recently, I have discovered that the dorsal and ventral pathways differentially contribute to different aspects of social visual perception. When observers perceived individual faces, I have found greater involvement of brain areas along the ventral pathway (shown as blue blobs and arrows in Images A and B below), greater involvement of areas along the dorsal pathway (shown as red blobs and arrows in Images A and B below) in the brain ([Im et al., 2017a](../Im_etal_NHB_2017.pdf)). For example, the fusiform gyrus in the ventral stream was more active (measured by fMRI), with lower temporal frequency (alpha frequency oscillations measured by MEG) during perception of an individual emotional face. On the other hand, the intraparietal sulcus in the dorsal stream was more active (measured by fMRI), with higher temporal frequency (beta frequency oscillations measured by MEG) during perception of a crowd of emotional faces. 
<div class="container"> 
  <div class="row" style="margin-bottom: 1px">
    <div class="col-md-12 col-sm-12">
        <img src="../images/MP-CE3.jpg" width="90%" />
    </div>
  </div>
</div>
My findings from fMRI and MEG suggest that both the dorsal and ventral pathways are involved in perceptual processing, but with differential contributions to perceiving and responding to individual faces and crowds of faces. 
<br/>

__* Action goals and motivations modulate how our eyes see and navigate a visual scene__<br/>


(_This work in this area received an ECOR Tosteson Postdoctoral Fellowship Award for Medical Discovery and was funded by Massachusetts General Hospital_). 
<br/>

------
## **3. Attentional distraction can facilitate perception and action.** {#Research_theme_3}
Although it is generally accepted, and usually valid, that distracted attention impairs perceptual and behavioral performance, I have found advantages of distributed (or distracted) attention over focused attention in some perceptual tasks and motor learning. For example, distributed attention facilitates global processing of a visual image and enhances memory retrieval of visually-guided actions that have been learned under similar distraction. These results suggest that as another processing route, distributed attention can enhance our perception and action under some circumstances in which focused attention may actually hinder performance. A broader attentional focus afforded by reduced control under distributed attention can allow us to learn more about the background and context of the environment, compared to the mode of focused attention. This line of research has led me to pursue one of my future research aims of characterizing how these non-selective and selective routes guide each other to support different aspects for our complex behaviors, with the goal of understanding how cognition modulates perception and action in our complex behaviors across a range of tasks. New findings from this research will contribute to better rehabilitation/training programs for patients with motor degenerative diseases and those who need to refine and adjust their perception-action coordination after injuries or surgeries 


(_This work in this area was recognized and supported by a Center for Vision Research Award at Brown University_). 

------
## **4. Individual differences in perception, cognition, and action.** {#Research_theme_4}



